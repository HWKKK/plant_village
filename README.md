# PlantVillage Disease Classification (plant_village)

PlantVillage 데이터셋의 이미지를 사용하여 식물 질병을 분류하는 프로젝트입니다. 
두 가지 접근 방식(직접 설계한 CNN, VGG16 전이학습)을 사용하여 모델을 학습하고 비교했습니다.

## 데모 영상

* [데모 영상 바로가기](https://youtu.be/0ZDLq__uQG8)

## 코드

학습 및 평가 코드는 저장소 내 Jupyter Notebook 파일에서 확인할 수 있습니다:

파일명: notebooks/FINAL_plant_village_non_preprocessing_ver2
* [코드 바로가기](./notebooks/FINAL_plant_village_non_preprocessing_ver2.ipynb)

## 모델 접근 방식 및 비교

이 프로젝트에서는 두 가지 주요 모델링 접근 방식을 시도하고 그 성능을 비교했습니다.

1.  **시도 1: 직접 설계한 CNN 모델**
    * 직접 CNN 아키텍처를 설계하여 처음부터 학습시킨 모델입니다.

2.  **시도 2: VGG16 전이학습 모델**
    * ImageNet으로 사전 훈련된 VGG16 모델을 기반으로 사용했습니다.
    * VGG16의 컨볼루션 베이스 가중치는 동결(freeze)하고, 모델 상단에 GlobalAveragePooling2D 레이어와 새로운 Dense 분류 레이어를 추가하여 학습했습니다.

### 성능 비교 요약

| 항목                    | 시도 1 (직접 설계 CNN)      | 시도 2 (VGG16 전이학습)       |
| :---------------------- | :-------------------------- | :---------------------------- |
| **최고 검증 정확도** | **~94.0%** (Epoch 9)        | ~93.4% (Epoch 20)             |
| **최저 검증 손실** | ~0.245 (Epoch 8)            | **~0.203** (Epoch 20)         |
| **종료 시점 (조기 종료)** | Epoch 11                    | Epoch 20                      |
| **과대적합** | **심각** | 최소                          |
| **Epoch 당 시간 (추정)** | ~45초                       | ~113초                        |
| **저장된 모델 성능** | ~93.7% Acc / 0.245 Loss     | ~93.4% Acc / 0.203 Loss       |

### 분석

* 두 모델 모두 약 93-94% 수준의 높은 검증 정확도를 달성했습니다.
* 직접 설계한 모델(시도 1)은 약간 더 높은 최고 검증 정확도에 빠르게 도달했지만, **심각한 과대적합** 경향을 보이며 훈련이 조기 종료되었습니다. (훈련 정확도는 99%에 육박했으나 검증 손실 증가)
* VGG16 전이학습 모델(시도 2)은 최고 정확도는 약간 낮았지만, **훨씬 낮은 최종 검증 손실**을 기록하며 과대적합을 효과적으로 억제했습니다. -> 더 나은 **일반화 성능**을 가졌을 가능성이 높음을 의미합니다.
* VGG16 모델은 사전 훈련된 특징을 활용하여 안정적인 학습을 보였으나, 모델 크기로 인해 Epoch 당 학습 시간은 더 길었습니다.

### 결론

직접 설계한 모델이 약간 더 높은 최고 정확도를 보였지만, **VGG16 전이학습 방식이 더 낮은 검증 손실과 뛰어난 과대적합 억제 능력을 보여주어 더 견고하고 일반화 성능이 우수한 모델**로 판단됩니다.

### 학습 곡선 시각화

**시도 1 (직접 설계 CNN):**

<img width="713" alt="attempt1" src="https://github.com/user-attachments/assets/b6122496-df53-4a39-a3a4-54f81511201b" />

**시도 2 (VGG16):**

<img width="707" alt="attempt2" src="https://github.com/user-attachments/assets/86a2f761-ead8-42e1-9391-6c552ac8e9ba" />

### 회고
- 홍지수
1. 배운점: 전이학습(VGG16)이 직접 설계 모델 대비 과대적합 억제 및 일반화 성능 확보에 더 효과적일 수 있음을 학습하였다. 최종 정확도뿐 아니라 검증 손실, 과대적합 여부 등 일반화 성능 지표가 중요하다!
2. 아쉬운점: 시간 제약으로 데이터셋 특성(분포, 이상치 등)에 대한 심층 분석이 부족했다.
3. 느낀점: 사전 훈련된 모델과 전이학습의 강력한 성능 및 개발 효율성을 체감하였다, 단순 정확도를 넘어 안정적인 학습과 일반화 성능 확보의 중요성을 느꼈다.
4. 어려웠던 점: VGG16 모델 학습 시, 성능이 점진적으로 향상되어 최적의 학습 종료 시점 판단이 어려웠다. 긴 Epoch당 학습 시간으로 인해 다양한 하이퍼파라미터 튜닝 실험에 제약이 발생했었다.

- 정원규
테스트 데이터를 포함한 전체 학습 이미지가 특정한 패턴(균일한 촬영 조건)을 띠고 있었고, 이에 따라 모델 테스트 정확도도 높게 나오는 반면 외부 이미지를 예측했을 때 잘못된 분류를 반복하였다. 서비스 측면에서 '이파리 한 장을 떼어 촬영하세요' 등 조건을 명시할 수도 있겠지만 모델 학습 입장에서는 증강을 거친다던지 좀 더 고도화된 작업을 거쳐야 실사용에 쓸만한 작업 결과를 얻을 수 있었을 것 같았다. 종합적으로 모델의 성능을 어떻게 평가할 것인지 고민이 좀 더 필요하다고 생각되었다.
